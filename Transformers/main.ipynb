{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee1c141-e573-4edc-aca7-3344bd3c9543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/app-root/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: torch in /opt/app-root/lib/python3.9/site-packages (2.4.1)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /opt/app-root/lib/python3.9/site-packages (3.9.2)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: torchvision in /opt/app-root/lib/python3.9/site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in /opt/app-root/lib/python3.9/site-packages (2.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/app-root/lib/python3.9/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/app-root/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/app-root/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/app-root/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/app-root/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: onnx in /opt/app-root/lib/python3.9/site-packages (1.16.0)\n",
      "Requirement already satisfied: onnxruntime in /opt/app-root/lib/python3.9/site-packages (1.19.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/app-root/lib/python3.9/site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/app-root/lib/python3.9/site-packages (from onnx) (4.25.3)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: flatbuffers in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/app-root/lib/python3.9/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.9/site-packages (1.34.111)\n",
      "Requirement already satisfied: botocore in /opt/app-root/lib/python3.9/site-packages (1.34.111)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/app-root/lib/python3.9/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.9/site-packages (from botocore) (1.26.18)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.9/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken torch requests matplotlib pandas --upgrade torch torchvision torchaudio \n",
    "!pip install onnx onnxruntime\n",
    "!pip install boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb61681-0469-4db4-9b05-e963cece1345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training Loss: 11.693 Validation Loss: 11.681\n",
      "Step: 20 Training Loss: 10.386 Validation Loss: 10.433\n",
      "Step: 40 Training Loss: 8.761 Validation Loss: 8.977\n",
      "Step: 60 Training Loss: 7.349 Validation Loss: 7.711\n",
      "Step: 80 Training Loss: 6.834 Validation Loss: 7.287\n",
      "Step: 100 Training Loss: 6.661 Validation Loss: 7.118\n",
      "Step: 120 Training Loss: 6.663 Validation Loss: 6.971\n",
      "Step: 140 Training Loss: 6.247 Validation Loss: 6.951\n",
      "Step: 160 Training Loss: 6.139 Validation Loss: 6.58\n",
      "Step: 180 Training Loss: 6.1 Validation Loss: 7.055\n",
      "Step: 200 Training Loss: 6.237 Validation Loss: 6.971\n",
      "Step: 220 Training Loss: 5.872 Validation Loss: 6.73\n",
      "Step: 240 Training Loss: 6.139 Validation Loss: 6.533\n",
      "Step: 260 Training Loss: 6.019 Validation Loss: 6.767\n",
      "Step: 280 Training Loss: 5.766 Validation Loss: 6.297\n",
      "Step: 300 Training Loss: 5.671 Validation Loss: 6.258\n",
      "Step: 320 Training Loss: 5.685 Validation Loss: 6.499\n",
      "Step: 340 Training Loss: 5.501 Validation Loss: 6.194\n",
      "Step: 360 Training Loss: 5.539 Validation Loss: 6.41\n",
      "Step: 380 Training Loss: 5.405 Validation Loss: 6.159\n",
      "Step: 400 Training Loss: 5.406 Validation Loss: 6.076\n",
      "Step: 420 Training Loss: 5.394 Validation Loss: 6.253\n",
      "Step: 440 Training Loss: 5.076 Validation Loss: 6.141\n",
      "Step: 460 Training Loss: 5.351 Validation Loss: 6.111\n",
      "Step: 480 Training Loss: 5.158 Validation Loss: 6.02\n",
      "Step: 500 Training Loss: 5.286 Validation Loss: 5.99\n",
      "Step: 520 Training Loss: 5.007 Validation Loss: 5.957\n",
      "Step: 540 Training Loss: 4.985 Validation Loss: 5.954\n",
      "Step: 560 Training Loss: 4.991 Validation Loss: 6.089\n",
      "Step: 580 Training Loss: 4.773 Validation Loss: 6.047\n",
      "Step: 600 Training Loss: 4.762 Validation Loss: 5.824\n",
      "Step: 620 Training Loss: 4.846 Validation Loss: 6.085\n",
      "Step: 640 Training Loss: 4.772 Validation Loss: 5.806\n",
      "Step: 660 Training Loss: 4.614 Validation Loss: 5.847\n",
      "Step: 680 Training Loss: 4.846 Validation Loss: 5.808\n",
      "Step: 700 Training Loss: 4.909 Validation Loss: 5.893\n",
      "Step: 720 Training Loss: 4.775 Validation Loss: 5.858\n",
      "Step: 740 Training Loss: 4.729 Validation Loss: 5.977\n",
      "Step: 760 Training Loss: 4.766 Validation Loss: 5.649\n",
      "Step: 780 Training Loss: 4.92 Validation Loss: 5.648\n",
      "Step: 800 Training Loss: 4.781 Validation Loss: 5.916\n",
      "Step: 820 Training Loss: 4.624 Validation Loss: 5.568\n",
      "Step: 840 Training Loss: 4.583 Validation Loss: 5.364\n",
      "Step: 860 Training Loss: 4.504 Validation Loss: 5.573\n",
      "Step: 880 Training Loss: 4.558 Validation Loss: 5.396\n",
      "Step: 900 Training Loss: 4.506 Validation Loss: 5.666\n",
      "Step: 920 Training Loss: 4.32 Validation Loss: 5.632\n",
      "Step: 940 Training Loss: 4.47 Validation Loss: 5.991\n",
      "Step: 960 Training Loss: 4.45 Validation Loss: 5.526\n",
      "Step: 980 Training Loss: 4.365 Validation Loss: 5.615\n",
      "Step: 1000 Training Loss: 4.464 Validation Loss: 5.4\n",
      "Step: 1020 Training Loss: 4.509 Validation Loss: 5.58\n",
      "Step: 1040 Training Loss: 4.333 Validation Loss: 5.728\n",
      "Step: 1060 Training Loss: 4.404 Validation Loss: 5.465\n",
      "Step: 1080 Training Loss: 4.198 Validation Loss: 5.617\n",
      "Step: 1100 Training Loss: 4.33 Validation Loss: 5.59\n",
      "Step: 1120 Training Loss: 4.059 Validation Loss: 5.524\n",
      "Step: 1140 Training Loss: 4.417 Validation Loss: 5.651\n",
      "Step: 1160 Training Loss: 3.955 Validation Loss: 5.523\n",
      "Step: 1180 Training Loss: 4.218 Validation Loss: 5.453\n",
      "Step: 1200 Training Loss: 4.072 Validation Loss: 5.554\n",
      "Step: 1220 Training Loss: 4.153 Validation Loss: 5.33\n",
      "Step: 1240 Training Loss: 4.422 Validation Loss: 5.288\n",
      "Step: 1260 Training Loss: 4.242 Validation Loss: 5.603\n",
      "Step: 1280 Training Loss: 4.127 Validation Loss: 5.16\n",
      "Step: 1300 Training Loss: 3.881 Validation Loss: 5.525\n",
      "Step: 1320 Training Loss: 4.15 Validation Loss: 5.425\n",
      "Step: 1340 Training Loss: 4.219 Validation Loss: 5.554\n",
      "Step: 1360 Training Loss: 3.867 Validation Loss: 5.402\n",
      "Step: 1380 Training Loss: 4.129 Validation Loss: 5.507\n",
      "Step: 1400 Training Loss: 4.239 Validation Loss: 5.711\n",
      "Step: 1420 Training Loss: 4.233 Validation Loss: 5.572\n",
      "Step: 1440 Training Loss: 3.854 Validation Loss: 5.249\n",
      "Step: 1460 Training Loss: 4.064 Validation Loss: 5.481\n",
      "Step: 1480 Training Loss: 3.987 Validation Loss: 5.044\n",
      "Step: 1500 Training Loss: 4.029 Validation Loss: 4.99\n",
      "Step: 1520 Training Loss: 4.126 Validation Loss: 5.188\n",
      "Step: 1540 Training Loss: 4.011 Validation Loss: 5.372\n",
      "Step: 1560 Training Loss: 3.825 Validation Loss: 5.288\n",
      "Step: 1580 Training Loss: 4.145 Validation Loss: 5.318\n",
      "Step: 1600 Training Loss: 3.812 Validation Loss: 5.354\n",
      "Step: 1620 Training Loss: 3.882 Validation Loss: 5.423\n",
      "Step: 1640 Training Loss: 3.635 Validation Loss: 5.191\n",
      "Step: 1660 Training Loss: 3.996 Validation Loss: 5.37\n",
      "Step: 1680 Training Loss: 3.78 Validation Loss: 5.511\n",
      "Step: 1700 Training Loss: 3.947 Validation Loss: 5.381\n",
      "Step: 1720 Training Loss: 3.823 Validation Loss: 5.536\n",
      "Step: 1740 Training Loss: 3.944 Validation Loss: 5.529\n",
      "Step: 1760 Training Loss: 3.819 Validation Loss: 5.101\n",
      "Step: 1780 Training Loss: 3.933 Validation Loss: 5.445\n",
      "Step: 1800 Training Loss: 4.064 Validation Loss: 5.154\n",
      "Step: 1820 Training Loss: 4.031 Validation Loss: 5.502\n",
      "Step: 1840 Training Loss: 3.729 Validation Loss: 5.299\n",
      "Step: 1860 Training Loss: 3.627 Validation Loss: 5.328\n",
      "Step: 1880 Training Loss: 4.132 Validation Loss: 5.224\n",
      "Step: 1900 Training Loss: 3.762 Validation Loss: 5.029\n",
      "Step: 1920 Training Loss: 3.557 Validation Loss: 5.151\n",
      "Step: 1940 Training Loss: 3.833 Validation Loss: 5.37\n",
      "Step: 1960 Training Loss: 3.951 Validation Loss: 5.217\n",
      "Step: 1980 Training Loss: 3.92 Validation Loss: 5.111\n",
      "Step: 2000 Training Loss: 3.905 Validation Loss: 5.259\n",
      "Step: 2020 Training Loss: 3.704 Validation Loss: 5.26\n",
      "Step: 2040 Training Loss: 3.895 Validation Loss: 5.288\n",
      "Step: 2060 Training Loss: 3.766 Validation Loss: 5.35\n",
      "Step: 2080 Training Loss: 3.653 Validation Loss: 5.386\n",
      "Step: 2100 Training Loss: 3.619 Validation Loss: 5.065\n",
      "Step: 2120 Training Loss: 3.719 Validation Loss: 5.115\n",
      "Step: 2140 Training Loss: 3.645 Validation Loss: 4.811\n",
      "Step: 2160 Training Loss: 3.655 Validation Loss: 5.293\n",
      "Step: 2180 Training Loss: 3.648 Validation Loss: 5.202\n",
      "Step: 2200 Training Loss: 3.82 Validation Loss: 5.407\n",
      "Step: 2220 Training Loss: 3.701 Validation Loss: 5.222\n",
      "Step: 2240 Training Loss: 3.746 Validation Loss: 5.2\n",
      "Step: 2260 Training Loss: 3.645 Validation Loss: 4.829\n",
      "Step: 2280 Training Loss: 3.671 Validation Loss: 4.974\n",
      "Step: 2300 Training Loss: 3.657 Validation Loss: 5.295\n",
      "Step: 2320 Training Loss: 3.553 Validation Loss: 4.891\n",
      "Step: 2340 Training Loss: 3.432 Validation Loss: 5.321\n",
      "Step: 2360 Training Loss: 3.793 Validation Loss: 5.396\n",
      "Step: 2380 Training Loss: 3.308 Validation Loss: 5.106\n",
      "Step: 2400 Training Loss: 3.346 Validation Loss: 5.172\n",
      "Step: 2420 Training Loss: 3.72 Validation Loss: 4.865\n",
      "Step: 2440 Training Loss: 3.458 Validation Loss: 5.064\n",
      "Step: 2460 Training Loss: 3.545 Validation Loss: 5.067\n",
      "Step: 2480 Training Loss: 3.52 Validation Loss: 5.047\n",
      "Step: 2500 Training Loss: 3.539 Validation Loss: 5.179\n",
      "Step: 2520 Training Loss: 3.546 Validation Loss: 4.931\n",
      "Step: 2540 Training Loss: 3.614 Validation Loss: 5.165\n",
      "Step: 2560 Training Loss: 3.582 Validation Loss: 5.081\n",
      "Step: 2580 Training Loss: 3.391 Validation Loss: 5.04\n",
      "Step: 2600 Training Loss: 3.539 Validation Loss: 5.16\n",
      "Step: 2620 Training Loss: 3.339 Validation Loss: 5.254\n",
      "Step: 2640 Training Loss: 3.435 Validation Loss: 4.992\n",
      "Step: 2660 Training Loss: 3.68 Validation Loss: 4.935\n",
      "Step: 2680 Training Loss: 3.414 Validation Loss: 4.915\n",
      "Step: 2700 Training Loss: 3.317 Validation Loss: 5.037\n",
      "Step: 2720 Training Loss: 3.446 Validation Loss: 5.266\n",
      "Step: 2740 Training Loss: 3.383 Validation Loss: 5.39\n",
      "Step: 2760 Training Loss: 3.389 Validation Loss: 5.032\n",
      "Step: 2780 Training Loss: 3.59 Validation Loss: 5.137\n",
      "Step: 2800 Training Loss: 3.396 Validation Loss: 5.089\n",
      "Step: 2820 Training Loss: 3.548 Validation Loss: 4.851\n",
      "Step: 2840 Training Loss: 3.275 Validation Loss: 4.832\n",
      "Step: 2860 Training Loss: 3.483 Validation Loss: 4.892\n",
      "Step: 2880 Training Loss: 3.596 Validation Loss: 4.746\n",
      "Step: 2900 Training Loss: 3.4 Validation Loss: 5.19\n",
      "Step: 2920 Training Loss: 3.47 Validation Loss: 4.761\n",
      "Step: 2940 Training Loss: 3.43 Validation Loss: 5.203\n",
      "Step: 2960 Training Loss: 3.484 Validation Loss: 5.022\n",
      "Step: 2980 Training Loss: 3.339 Validation Loss: 5.346\n",
      "Step: 3000 Training Loss: 3.614 Validation Loss: 5.218\n",
      "Step: 3020 Training Loss: 3.323 Validation Loss: 4.905\n",
      "Step: 3040 Training Loss: 3.225 Validation Loss: 4.957\n",
      "Step: 3060 Training Loss: 3.609 Validation Loss: 5.195\n",
      "Step: 3080 Training Loss: 3.458 Validation Loss: 4.984\n",
      "Step: 3100 Training Loss: 3.288 Validation Loss: 5.155\n",
      "Step: 3120 Training Loss: 3.096 Validation Loss: 4.861\n",
      "Step: 3140 Training Loss: 3.159 Validation Loss: 4.987\n",
      "Step: 3160 Training Loss: 3.429 Validation Loss: 4.974\n",
      "Step: 3180 Training Loss: 3.441 Validation Loss: 5.152\n",
      "Step: 3200 Training Loss: 3.337 Validation Loss: 5.247\n",
      "Step: 3220 Training Loss: 3.337 Validation Loss: 5.449\n",
      "Step: 3240 Training Loss: 3.434 Validation Loss: 5.024\n",
      "Step: 3260 Training Loss: 3.11 Validation Loss: 4.886\n",
      "Step: 3280 Training Loss: 3.332 Validation Loss: 4.984\n",
      "Step: 3300 Training Loss: 2.957 Validation Loss: 4.921\n",
      "Step: 3320 Training Loss: 3.342 Validation Loss: 5.039\n",
      "Step: 3340 Training Loss: 3.101 Validation Loss: 4.891\n",
      "Step: 3360 Training Loss: 2.936 Validation Loss: 4.813\n",
      "Step: 3380 Training Loss: 3.245 Validation Loss: 5.14\n",
      "Step: 3400 Training Loss: 3.409 Validation Loss: 4.944\n",
      "Step: 3420 Training Loss: 3.207 Validation Loss: 5.031\n",
      "Step: 3440 Training Loss: 3.314 Validation Loss: 5.005\n",
      "Step: 3460 Training Loss: 3.186 Validation Loss: 4.914\n",
      "Step: 3480 Training Loss: 3.278 Validation Loss: 4.685\n",
      "Step: 3500 Training Loss: 3.133 Validation Loss: 4.887\n",
      "Step: 3520 Training Loss: 3.251 Validation Loss: 4.959\n",
      "Step: 3540 Training Loss: 3.26 Validation Loss: 4.839\n",
      "Step: 3560 Training Loss: 3.06 Validation Loss: 4.95\n",
      "Step: 3580 Training Loss: 3.069 Validation Loss: 4.916\n",
      "Step: 3600 Training Loss: 3.253 Validation Loss: 4.953\n",
      "Step: 3620 Training Loss: 3.186 Validation Loss: 4.896\n",
      "Step: 3640 Training Loss: 3.099 Validation Loss: 4.845\n",
      "Step: 3660 Training Loss: 3.211 Validation Loss: 4.559\n",
      "Step: 3680 Training Loss: 3.213 Validation Loss: 4.938\n",
      "Step: 3700 Training Loss: 3.16 Validation Loss: 4.936\n",
      "Step: 3720 Training Loss: 3.223 Validation Loss: 5.237\n",
      "Step: 3740 Training Loss: 3.177 Validation Loss: 5.205\n",
      "Step: 3760 Training Loss: 3.239 Validation Loss: 4.889\n",
      "Step: 3780 Training Loss: 3.049 Validation Loss: 5.303\n",
      "Step: 3800 Training Loss: 3.24 Validation Loss: 4.797\n",
      "Step: 3820 Training Loss: 3.083 Validation Loss: 4.946\n",
      "Step: 3840 Training Loss: 3.327 Validation Loss: 4.904\n",
      "Step: 3860 Training Loss: 2.999 Validation Loss: 4.869\n",
      "Step: 3880 Training Loss: 3.039 Validation Loss: 4.852\n",
      "Step: 3900 Training Loss: 3.306 Validation Loss: 5.028\n",
      "Step: 3920 Training Loss: 3.328 Validation Loss: 4.826\n",
      "Step: 3940 Training Loss: 3.129 Validation Loss: 4.741\n",
      "Step: 3960 Training Loss: 3.029 Validation Loss: 5.092\n",
      "Step: 3980 Training Loss: 3.081 Validation Loss: 4.851\n",
      "Step: 4000 Training Loss: 2.961 Validation Loss: 4.993\n",
      "Step: 4020 Training Loss: 3.283 Validation Loss: 4.787\n",
      "Step: 4040 Training Loss: 3.113 Validation Loss: 4.596\n",
      "Step: 4060 Training Loss: 3.249 Validation Loss: 5.161\n",
      "Step: 4080 Training Loss: 2.94 Validation Loss: 4.814\n",
      "Step: 4100 Training Loss: 2.999 Validation Loss: 4.861\n",
      "Step: 4120 Training Loss: 2.992 Validation Loss: 4.939\n",
      "Step: 4140 Training Loss: 2.947 Validation Loss: 4.674\n",
      "Step: 4160 Training Loss: 3.292 Validation Loss: 5.498\n",
      "Step: 4180 Training Loss: 2.893 Validation Loss: 5.208\n",
      "Step: 4200 Training Loss: 3.215 Validation Loss: 4.937\n",
      "Step: 4220 Training Loss: 2.983 Validation Loss: 5.003\n",
      "Step: 4240 Training Loss: 2.812 Validation Loss: 4.979\n",
      "Step: 4260 Training Loss: 3.103 Validation Loss: 5.004\n",
      "Step: 4280 Training Loss: 3.098 Validation Loss: 5.11\n",
      "Step: 4300 Training Loss: 3.11 Validation Loss: 5.123\n",
      "Step: 4320 Training Loss: 3.021 Validation Loss: 5.003\n",
      "Step: 4340 Training Loss: 3.15 Validation Loss: 5.128\n",
      "Step: 4360 Training Loss: 3.041 Validation Loss: 4.92\n",
      "Step: 4380 Training Loss: 2.961 Validation Loss: 4.514\n",
      "Step: 4400 Training Loss: 3.026 Validation Loss: 4.951\n",
      "Step: 4420 Training Loss: 3.022 Validation Loss: 4.659\n",
      "Step: 4440 Training Loss: 2.972 Validation Loss: 4.716\n",
      "Step: 4460 Training Loss: 3.033 Validation Loss: 4.764\n",
      "Step: 4480 Training Loss: 3.058 Validation Loss: 4.88\n",
      "Step: 4500 Training Loss: 3.043 Validation Loss: 4.877\n",
      "Step: 4520 Training Loss: 3.002 Validation Loss: 4.999\n",
      "Step: 4540 Training Loss: 3.116 Validation Loss: 4.659\n",
      "Step: 4560 Training Loss: 2.875 Validation Loss: 4.984\n",
      "Step: 4580 Training Loss: 2.921 Validation Loss: 5.118\n",
      "Step: 4600 Training Loss: 3.109 Validation Loss: 4.985\n",
      "Step: 4620 Training Loss: 2.952 Validation Loss: 4.795\n",
      "Step: 4640 Training Loss: 2.985 Validation Loss: 4.93\n",
      "Step: 4660 Training Loss: 2.917 Validation Loss: 5.14\n",
      "Step: 4680 Training Loss: 3.072 Validation Loss: 4.688\n",
      "Step: 4700 Training Loss: 2.881 Validation Loss: 5.173\n",
      "Step: 4720 Training Loss: 3.06 Validation Loss: 5.416\n",
      "Step: 4740 Training Loss: 2.985 Validation Loss: 5.15\n",
      "Step: 4760 Training Loss: 3.087 Validation Loss: 4.742\n",
      "Step: 4780 Training Loss: 2.983 Validation Loss: 4.542\n",
      "Step: 4800 Training Loss: 3.091 Validation Loss: 4.942\n",
      "Step: 4820 Training Loss: 2.918 Validation Loss: 5.202\n",
      "Step: 4840 Training Loss: 2.885 Validation Loss: 5.245\n",
      "Step: 4860 Training Loss: 2.938 Validation Loss: 4.878\n",
      "Step: 4880 Training Loss: 2.961 Validation Loss: 5.085\n",
      "Step: 4900 Training Loss: 3.024 Validation Loss: 4.729\n",
      "Step: 4920 Training Loss: 2.853 Validation Loss: 4.816\n",
      "Step: 4940 Training Loss: 2.938 Validation Loss: 4.986\n",
      "Step: 4960 Training Loss: 2.997 Validation Loss: 5.103\n",
      "Step: 4980 Training Loss: 3.016 Validation Loss: 5.056\n",
      "Step: 4999 Training Loss: 3.084 Validation Loss: 4.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2118/3838840168.py:80: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert T <= self.context_length\n",
      "/tmp/ipykernel_2118/3838840168.py:81: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert C == self.d_model\n",
      "/tmp/ipykernel_2118/3838840168.py:87: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  weights = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
      "/opt/app-root/lib64/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:314: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/opt/app-root/lib64/python3.9/site-packages/torch/onnx/utils.py:739: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/opt/app-root/lib64/python3.9/site-packages/torch/onnx/utils.py:1237: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  params_dict = _C._jit_pass_onnx_constant_fold(\n",
      "/opt/app-root/lib64/python3.9/site-packages/torch/onnx/utils.py:1244: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been exported to models/mayank-test-1/transformer_language_model.onnx\n",
      "---------------\n",
      "who is the best sales person in convincing potential solutions and convince their communication style.\n",
      "1. This not only this stage allows the pis ofot responses, making the purchase decision-making professional easier to make them more likely to determine, understanding. It is not only demonstrates respect that is received and are effective questions to face-to-face to meeting your explanations. Actively listening to their words and experiences of each customer's background or desires to meeting their thoughts. Additionally, be familiarize the Value of the sales process, hear solution presents powerful for\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import math\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4  # How many batches per training step\n",
    "context_length = 16  # Length of the token chunk each batch\n",
    "d_model = 64  # The size of our model token embeddings\n",
    "num_blocks = 8  # Number of transformer blocks\n",
    "num_heads = 4  # Number of heads in Multi-head attention\n",
    "learning_rate = 1e-3  # 0.001\n",
    "dropout = 0.1  # Dropout rate\n",
    "max_iters = 5000  # Total of training iterations <- Change this to smaller number for testing\n",
    "eval_interval = 50  # How often to evaluate\n",
    "eval_iters = 20  # Number of iterations to average for evaluation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if it's available.\n",
    "TORCH_SEED = 1337\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "# Load training data\n",
    "if not os.path.exists('data/sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'\n",
    "    with open('data/sales_textbook.txt', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "\n",
    "with open('data/sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Using TikToken (Same as GPT3) to tokenize the source text\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = encoding.encode(text)\n",
    "max_token_value = max(tokenized_text) + 1  # the maximum value of the tokenized numbers\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long, device=device)  # put tokenized text into tensor\n",
    "\n",
    "# Split train and validation\n",
    "split_idx = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]\n",
    "\n",
    "\n",
    "# Define Feed Forward Network\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = dropout\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(in_features=self.d_model, out_features=self.d_model * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=self.d_model * 4, out_features=self.d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "\n",
    "# Define Scaled Dot Product Attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, head_size: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.head_size = head_size\n",
    "        self.context_length = context_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.key_layer = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n",
    "        self.query_layer = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n",
    "        self.value_layer = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(\n",
    "            torch.ones((self.context_length, self.context_length))))  # Lower triangular mask\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape  # Batch size, Time steps(current context_length), Channels(dimensions)\n",
    "        assert T <= self.context_length\n",
    "        assert C == self.d_model\n",
    "        q = self.query_layer(x)\n",
    "        k = self.key_layer(x)\n",
    "        v = self.value_layer(x)\n",
    "\n",
    "        # Scaled dot product attention: Q @ K^T / sqrt(d_k)\n",
    "        weights = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        # Apply masked attention\n",
    "        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        weights = F.softmax(input=weights, dim=-1)\n",
    "        weights = self.dropout_layer(weights)\n",
    "\n",
    "        # Apply dot product attention: weights @ V\n",
    "        out = weights @ v\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head_size: int):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = head_size\n",
    "        self.d_model = d_model\n",
    "        self.context_length = context_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.heads = nn.ModuleList([Attention(head_size=self.head_size) for _ in range(self.num_heads)])\n",
    "        self.projection_layer = nn.Linear(in_features=self.d_model, out_features=self.d_model)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.projection_layer(out)\n",
    "        out = self.dropout_layer(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.context_length = context_length\n",
    "        self.head_size = d_model // num_heads  # head size should be divisible by d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.multi_head_attention_layer = MultiHeadAttention(head_size=self.head_size)\n",
    "        self.feed_forward_layer = FeedForward()\n",
    "        self.layer_norm_1 = nn.LayerNorm(normalized_shape=self.d_model)\n",
    "        self.layer_norm_2 = nn.LayerNorm(normalized_shape=self.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Note: The order of the operations is different from the original Transformer paper\n",
    "        # The order here is: LayerNorm -> Multi-head attention -> LayerNorm -> Feed forward\n",
    "        x = x + self.multi_head_attention_layer(self.layer_norm_1(x))  # Residual connection\n",
    "        x = x + self.feed_forward_layer(self.layer_norm_2(x))  # Residual connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.context_length = context_length\n",
    "        self.num_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "        self.dropout = dropout\n",
    "        self.max_token_value = max_token_value\n",
    "        # Set up token embedding look-up table\n",
    "        self.token_embedding_lookup_table = nn.Embedding(num_embeddings=self.max_token_value + 1, embedding_dim=self.d_model)\n",
    "\n",
    "        # Run all the transformer blocks\n",
    "        # Different from original paper, here we add a final layer norm after all the blocks\n",
    "        self.transformer_blocks = nn.Sequential(*(\n",
    "                [TransformerBlock(num_heads=self.num_heads) for _ in range(self.num_blocks)] +\n",
    "                [nn.LayerNorm(self.d_model)]\n",
    "        ))\n",
    "        self.language_model_out_linear_layer = nn.Linear(in_features=self.d_model, out_features=self.max_token_value)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \"\"\"\n",
    "        # Set up position embedding look-up table\n",
    "        # following the same approach as the original Transformer paper (Sine and Cosine functions)\n",
    "        \"\"\"\n",
    "        position_encoding_lookup_table = torch.zeros(self.context_length, self.d_model)\n",
    "        position = torch.arange(0, self.context_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
    "        position_encoding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
    "        position_encoding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
    "        # change position_encoding_lookup_table from (context_length, d_model) to (T, d_model)\n",
    "        position_embedding = position_encoding_lookup_table[:T, :].to(device)\n",
    "        x = self.token_embedding_lookup_table(idx) + position_embedding\n",
    "        x = self.transformer_blocks(x)\n",
    "        # The \"logits\" are the output values of our model before applying softmax\n",
    "        logits = self.language_model_out_linear_layer(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits_reshaped = logits.view(B * T, C)\n",
    "            targets_reshaped = targets.view(B * T)\n",
    "            loss = F.cross_entropy(input=logits_reshaped, target=targets_reshaped)\n",
    "        else:\n",
    "            loss = None\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop idx to the max size of our positional embeddings table\n",
    "            idx_crop = idx[:, -self.context_length:]\n",
    "            # Get predictions\n",
    "            logits, loss = self(idx_crop)\n",
    "            # Get the last time step from logits where the dimensions of the logits are (B,T,C)\n",
    "            logits_last_timestep = logits[:, -1, :]\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = F.softmax(input=logits_last_timestep, dim=-1)\n",
    "            # Sample from the probabilities' distribution.\n",
    "            idx_next = torch.multinomial(input=probs, num_samples=1)\n",
    "            # Append the sampled indexes idx_next to idx\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerLanguageModel()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Get input embedding batch\n",
    "def get_batch(split: str):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n",
    "    x = torch.stack([data[idx:idx + context_length] for idx in idxs]).to(device)\n",
    "    y = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs]).to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Calculate loss\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'valid']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x_batch, y_batch = get_batch(split)\n",
    "            logits, loss = model(x_batch, y_batch)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
    "tracked_losses = list()\n",
    "for step in range(max_iters):\n",
    "    if step % eval_iters == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        tracked_losses.append(losses)\n",
    "        print('Step:', step, 'Training Loss:', round(losses['train'].item(), 3), 'Validation Loss:',\n",
    "              round(losses['valid'].item(), 3))\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), 'model-ckpt.pt')\n",
    "\n",
    "# Export the model to ONNX format\n",
    "# Prepare a sample input tensor\n",
    "sample_batch_size = 1\n",
    "sample_context_length = context_length\n",
    "dummy_input = torch.randint(\n",
    "    low=0,\n",
    "    high=max_token_value,\n",
    "    size=(sample_batch_size, sample_context_length),\n",
    "    dtype=torch.long,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Export the model\n",
    "onnx_filename = 'models/mayank-test-1/transformer_language_model.onnx'\n",
    "torch.onnx.export(\n",
    "    model,                # The model to be exported\n",
    "    dummy_input,          # The dummy input tensor\n",
    "    onnx_filename,        # Where to save the ONNX model\n",
    "    export_params=True,   # Store the trained parameter weights inside the model file\n",
    "    opset_version=13,     # ONNX opset version to export the model\n",
    "    do_constant_folding=True,  # Whether to execute constant folding for optimization\n",
    "    input_names=['input'],     # The model's input names\n",
    "    output_names=['output'],   # The model's output names\n",
    "    dynamic_axes={\n",
    "        'input': {1: 'sequence_length'},   # Variable sequence length\n",
    "        'output': {1: 'sequence_length'}\n",
    "    }\n",
    ")\n",
    "print(f\"Model has been exported to {onnx_filename}\")\n",
    "\n",
    "# Generate\n",
    "model.eval()\n",
    "start = 'who is the best sales person'\n",
    "start_ids = encoding.encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "y = model.generate(x, max_new_tokens=100)\n",
    "print('---------------')\n",
    "print(encoding.decode(y[0].tolist()))\n",
    "print('---------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3988dc0-d1a9-42a7-ac65-684ba3266e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0Hl0BRaMg_SAzJZe\n",
      "JVwHJQxF3glbm6RzuzW3iNech4wPxrlE\n",
      "https://minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu\n",
      "us-east-1\n",
      "my-storage\n",
      "s3.Bucket(name='my-storage')\n",
      "models/mayank-test-1/transformer_language_model.onnx -> models/mayank-test-1/transformer_language_model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/fraud/1/model.onnx -> models/fraud/1/model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "#UPload compiled model to s3\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "\n",
    "print(aws_access_key_id)\n",
    "print(aws_secret_access_key)\n",
    "print(endpoint_url)\n",
    "print(region_name)\n",
    "print(bucket_name)\n",
    "\n",
    "if not all([aws_access_key_id, aws_secret_access_key, endpoint_url, region_name, bucket_name]):\n",
    "    raise ValueError(\"One or data connection variables are empty.  \"\n",
    "                     \"Please check your data connection to an S3 bucket.\")\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=aws_access_key_id,\n",
    "                                aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name,\n",
    "    verify=False)\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "print(bucket)\n",
    "\n",
    "def upload_directory_to_s3 (local_directory, s3_prefix):\n",
    "    num_files = 0\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "            num_files += 1\n",
    "    return num_files\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)\n",
    "\n",
    "\n",
    "local_models_directory = \"models\"\n",
    "\n",
    "if not os.path.isdir(local_models_directory):\n",
    "    raise ValueError(f\"The directory '{local_models_directory}' does not exist.  \"\n",
    "                     \"Did you finish training the model in the previous notebook?\")\n",
    "\n",
    "num_files = upload_directory_to_s3(\"models\", \"models\")\n",
    "\n",
    "if num_files == 0:\n",
    "    raise ValueError(\"No files uploaded.  Did you finish training and \"\n",
    "                     \"saving the model to the \\\"models\\\" directory?  \"\n",
    "                     \"Check for \\\"models/fraud/1/model.onnx\\\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de58c80d-d366-4ea5-a4ef-a44b880c699d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/fraud/1/model.onnx\n",
      "models/mayank-test-1/transformer_language_model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-s3-fraud-detection.apps.c01.eu-west-03.openshift.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "list_objects(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0445c7-ea45-4516-a105-4d16143444ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
